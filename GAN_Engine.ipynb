{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlmondGod/GAN-Engine/blob/main/GAN_Engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN Engine\n",
        "Hi! Welcome to my NumPy GAN Engine! To use, import your data however you'd prefer, select yoru chosen activation and cost functions in \"Generator Instantiation\" and \"Discriminator Instantiation\" (it is recommended to keep ReLU!), and select your Optimizer! Then, adjust the training parameters and simply run the training loop!\n",
        "\n",
        "###Currently Available:\n",
        "\n",
        "**Loss Functions:** Quadratic, Binary Cross Entropy\n",
        "\n",
        "**Activation Functions:** Linear, Sigmoid\n",
        "\n",
        "**Optional Output Functions:** ReLU, Postlinear, Dropout\n",
        "\n",
        "**Optimizers:** SGD, Adam\n"
      ],
      "metadata": {
        "id": "3WyLXfVRRbnB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEGC6Me-Wcgc"
      },
      "source": [
        "#### Initialize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIRYnrH76rXt",
        "outputId": "a5273a71-fb50-4dd4-8de7-88da0a33d4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import matplotlib\n",
        "from socket import socket\n",
        "\n",
        "data_length = 1024\n",
        "\n",
        "train_input = np.zeros((data_length, 2))\n",
        "\n",
        "train_labels = np.zeros(data_length)\n",
        "\n",
        "#train data is tuples of (input, labels)\n",
        "train_data = np.zeros((data_length, 2, 2))\n",
        "\n",
        "for i in range(data_length):\n",
        "  train_input[i][0] = random.random() * 10\n",
        "  train_input[i][1] = math.sin(train_input[i][0])\n",
        "  matplotlib.pyplot.plot(train_input[i][0], train_input[i][1], \".\")\n",
        "  train_data[i][0] = train_input[i];\n",
        "  train_data[i][1] = train_labels[i];\n",
        "\n",
        "print(train_labels)\n",
        "\n",
        "#skip tags for now\n",
        "#input_tags = np.zeros(data_length, 2)\n",
        "\n",
        "# training_data = [(train_data, input_tags) for i in data_length]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6SorvfyWV69"
      },
      "source": [
        "#### Process Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfJJ_vnqArj-"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "#loads training data into batches to be iterated on\n",
        "def train_loader(train_data, batch_size):\n",
        "\n",
        "  #shuffle data to randomize\n",
        "  random.shuffle(train_data)\n",
        "\n",
        "  #data is tensor with batch_size batches, as many as fit in each batch, and\n",
        "    #train_data dimensions 2,2 for each element\n",
        "  batch_number = (int) (data_length/batch_size)\n",
        "  processed_data = np.zeros((batch_number, batch_size, 2, 2))\n",
        "  current_data_size = 0\n",
        "\n",
        "  #put data into batches\n",
        "  for i in range(batch_number):\n",
        "    for j in range(batch_size):\n",
        "      processed_data[i][j] = train_data[current_data_size];\n",
        "      current_data_size += 1\n",
        "\n",
        "  return processed_data\n",
        "\n",
        "# stringtest = str(train_loader(train_data, batch_size)[1])\n",
        "# print(stringtest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w-b1CnjWOQY"
      },
      "source": [
        "#### Output and Activation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G2an62rX72N"
      },
      "outputs": [],
      "source": [
        "#ReLU of linear activation\n",
        "#purpose is to solve vanishing gradients\n",
        "def ReLU(input):\n",
        "  return max(0, input)\n",
        "\n",
        "#input should be same dimension as the layer's weight and bias' 2nd dimension\n",
        "#weight and bias are the matrices for 1 layer\n",
        "def LinearActivation(weights, biases, input, relu):\n",
        "  #instantiate matrix of vector of weighted inputs and vector of outputs\n",
        "  output_matrices = [[] for _ in range(len(weights))]\n",
        "  output = np.zeros(len(weights))\n",
        "\n",
        "  #for each neuron\n",
        "  for i in range(len(weights)):\n",
        "    #apply weight and bias to each input\n",
        "    output_matrices[i] = np.add((np.dot(weights[i], input)), biases[i])\n",
        "    #sum weighted outputs into scalar output for each neuron\n",
        "    for j in range(len(output_matrices[i])):\n",
        "      output[i] += output_matrices[i][j]\n",
        "\n",
        "    if(relu):\n",
        "      #apply ReLU to each neuron output\n",
        "      output[i] = ReLU(output[i])\n",
        "\n",
        "  return output\n",
        "\n",
        "#Randomly zeroes some of the elements of the input with probability p\n",
        "  #When using this, also use Postdropout\n",
        "#purpose is to prevent coadaptation of neurons (encourage independent neurons)\n",
        "def Dropout(p, input):\n",
        "  for i in range(len(input)):\n",
        "    if (random.random() < p):#if RV = 1 (with probability p)\n",
        "      input[i] = 0\n",
        "  return input\n",
        "\n",
        "#Scale outputs by a factor of 1/(1-p) (this is part of Dropout)\n",
        "def Postdropout(p, output):\n",
        "  for i in range(len(output)):\n",
        "    output[i] = output[i] * (1.0/(1.0-p))\n",
        "  return output\n",
        "\n",
        "#applies sigmoid function 1/(1-e^(-x)) to a layer's output\n",
        "def Sigmoid(output):\n",
        "  for i in range(len(output)):\n",
        "    # print(output[i])\n",
        "    # if(output[i] < -1000):\n",
        "    #   output[i] = 0.00001\n",
        "    # elif(output[i] > 700):\n",
        "    #   output[i] = 0.99999\n",
        "    # else:\n",
        "    if (output[i] < 0):\n",
        "      output[i] = 1 - (1/(1 + math.exp(output[i])))\n",
        "    else:\n",
        "      output[i] = 1/(1 + math.exp(-(output[i])))\n",
        "\n",
        "    #correct\n",
        "    # if(output[i] == 1):\n",
        "    #   output[i] = 0.99\n",
        "    if(output[i] == 0):\n",
        "      output[i] = 0.001\n",
        "\n",
        "  return output\n",
        "\n",
        "def SigmoidPrime(output):\n",
        "  output = Sigmoid(output)\n",
        "  multipliers = [None] * len(output)\n",
        "  for o,_ in enumerate(output):\n",
        "    multipliers[o] = 1 - output[o]\n",
        "    output[o] = output[o] * multipliers[o]\n",
        "\n",
        "  return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUmdUcT6V-l7"
      },
      "source": [
        "#### Generator Instantiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qk2JkBXOGNX0"
      },
      "outputs": [],
      "source": [
        "class Generator():\n",
        "  def __init__(self):\n",
        "    self.layersizes = [2, 2, 4, 2]\n",
        "    self.num_layers = len(self.layersizes)\n",
        "\n",
        "    #get size of largest layer\n",
        "    largest_layer = 0\n",
        "    for j in self.layersizes:\n",
        "      if(largest_layer < j):\n",
        "        largest_layer = j\n",
        "\n",
        "    self.total_weights = [[] for _ in range(self.num_layers)]\n",
        "    self.total_biases = [[] for _ in range(self.num_layers)]\n",
        "\n",
        "    self.zs = [[] for _ in range(self.num_layers)]\n",
        "    self.activations = [[] for _ in range(self.num_layers)]\n",
        "\n",
        "    #use He weight initialization and bias initialization for each layer\n",
        "    for i in range(0, self.num_layers):\n",
        "      #number of neurons in this layer\n",
        "      num_neurons = self.layersizes[i]\n",
        "\n",
        "      #number of inputs to this layer\n",
        "      if(i >= 1): num_inputs = self.layersizes[i - 1]\n",
        "      else: num_inputs = len(train_input[0])\n",
        "\n",
        "      #this is the matrix of weights and biases for one layer\n",
        "      self.weights = np.zeros((num_neurons, num_inputs))\n",
        "      self.biases = np.zeros((num_neurons, num_inputs))\n",
        "\n",
        "      #for each neuron in the layer\n",
        "      for j in range(0, num_neurons):\n",
        "        #initialize this layer of weights + biases (array of neuron arrays)\n",
        "        weights_layer = np.zeros(num_inputs)\n",
        "        biases_layer = np.zeros(num_inputs)\n",
        "\n",
        "        for k in range(0, num_inputs):\n",
        "          #initialize weight and bias for each neuron to He initialization\n",
        "          weights_layer[k] = random.normalvariate(0, (2/num_neurons))\n",
        "          biases_layer[k] = random.normalvariate(0, (2/num_neurons))\n",
        "\n",
        "        self.weights[j] = weights_layer\n",
        "        self.biases[j] = biases_layer\n",
        "\n",
        "      self.total_weights[i] = self.weights\n",
        "      self.total_biases[i] = self.biases\n",
        "      # print(self.total_weights[i])\n",
        "      # print(self.total_biases[i])\n",
        "\n",
        "  #data is one element in the batch\n",
        "  def forward(self, input):\n",
        "    #feed input into first layer\n",
        "    weights_input = self.total_weights[0]\n",
        "    biases_input = self.total_biases[0]\n",
        "    output = LinearActivation(weights_input, biases_input, input, False)\n",
        "    self.zs[0] = output#store zs (pre-activation function output) for this layer\n",
        "    # output = Sigmoid(output)\n",
        "    self.activations[0] = output\n",
        "    for i in range(1, (self.num_layers - 1)):\n",
        "      weights_input = self.total_weights[i]\n",
        "      biases_input = self.total_biases[i]\n",
        "      output = LinearActivation(weights_input, biases_input, output, False)\n",
        "      self.zs[i] = output#store zs (pre-activation function output) for this layer\n",
        "      # output = Sigmoid(output)\n",
        "      self.activations[i] = output\n",
        "\n",
        "    #no ReLU on last layer\n",
        "    weights_input = self.total_weights[self.num_layers - 1]\n",
        "    biases_input = self.total_biases[self.num_layers - 1]\n",
        "    output = LinearActivation(weights_input, biases_input, output, False)\n",
        "    self.zs[self.num_layers - 1] = output#store zs (pre-activation function output) for this layer\n",
        "    self.activations[self.num_layers - 1] = output\n",
        "\n",
        "    return output\n",
        "\n",
        "# generator = Generator()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn4P_CufGDDA"
      },
      "source": [
        "#### Discriminator Instantiation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2H_IVbQrCTC"
      },
      "outputs": [],
      "source": [
        "from IPython.core.display import display_png\n",
        "class Discriminator:\n",
        "  def __init__(self):\n",
        "    self.layersizes = [2, 16, 8, 1]\n",
        "    self.num_layers = len(self.layersizes)\n",
        "\n",
        "    #get size of largest layer\n",
        "    largest_layer = 0\n",
        "    for j in self.layersizes:\n",
        "      if(largest_layer < j):\n",
        "        largest_layer = j\n",
        "\n",
        "    self.total_weights = [[] for _ in range(self.num_layers)]\n",
        "    self.total_biases = [[] for _ in range(self.num_layers)]\n",
        "\n",
        "    self.activations = [[] for _ in range(self.num_layers)]\n",
        "    self.zs = [[] for _ in range(self.num_layers)]\n",
        "\n",
        "    #use He weight initialization and bias initialization for each layer\n",
        "    for i in range(0, self.num_layers):\n",
        "      #number of neurons in this layer\n",
        "      num_neurons = self.layersizes[i]\n",
        "\n",
        "      #number of inputs to this layer\n",
        "      if(i >= 1): num_inputs = self.layersizes[i - 1]\n",
        "      else: num_inputs = len(train_input[0])\n",
        "\n",
        "      #this is the matrix of weights and biases for one layer\n",
        "      self.weights = np.zeros((num_neurons, num_inputs))\n",
        "      self.biases = np.zeros((num_neurons, num_inputs))\n",
        "\n",
        "      #for each neuron in the layer\n",
        "      for j in range(0, num_neurons):\n",
        "        #initialize this layer of weights + biases (array of neuron arrays)\n",
        "        weights_layer = np.zeros(num_inputs)\n",
        "        biases_layer = np.zeros(num_inputs)\n",
        "\n",
        "        for k in range(0, num_inputs):\n",
        "          #initialize weight and bias for each neuron to He initialization\n",
        "          weights_layer[k] = random.normalvariate(0, (2/num_neurons))\n",
        "          biases_layer[k] = random.normalvariate(0, (2/num_neurons))\n",
        "\n",
        "        self.weights[j] = weights_layer\n",
        "        self.biases[j] = biases_layer\n",
        "\n",
        "      self.total_weights[i] = self.weights\n",
        "      self.total_biases[i] = self.biases\n",
        "      # print(self.total_weights[i])\n",
        "      # print(self.total_biases[i])\n",
        "\n",
        "      #data is one element in the batch\n",
        "  #data is one element in the batch\n",
        "  def forward(self, input):\n",
        "    #feed input into first layer\n",
        "    weights_input = self.total_weights[0]\n",
        "    biases_input = self.total_biases[0]\n",
        "    output = LinearActivation(weights_input, biases_input, input, False)\n",
        "    # output = Sigmoid(output)\n",
        "    self.zs[0] = output#store zs (pre-activation function output) for this layer\n",
        "    self.activations[0] = output\n",
        "    for i in range(1, (self.num_layers - 1)):\n",
        "      weights_input = self.total_weights[i]\n",
        "      biases_input = self.total_biases[i]\n",
        "      # output = Dropout(0.3, output) #apply dropout to input\n",
        "      output = LinearActivation(weights_input, biases_input, output, False)\n",
        "      self.zs[i] = output#store zs (pre-activation function output) for this layer\n",
        "      # output = Sigmoid(output)\n",
        "      # output = Postdropout(0.3, output) #apply postdropout to input\n",
        "      self.activations[i] = output#store activations for this layer\n",
        "\n",
        "\n",
        "    #no ReLU or Dropout on last layer, Sigmoid on last layer\n",
        "    weights_input = self.total_weights[self.num_layers - 1]\n",
        "    biases_input = self.total_biases[self.num_layers - 1]\n",
        "    output = LinearActivation(weights_input, biases_input, output, False)\n",
        "    self.zs[self.num_layers - 1] = output#store zs (pre-activation function output) for this layer\n",
        "    # print(\"HELLO\")\n",
        "    # print(self.total_weights)\n",
        "    # print(output)\n",
        "    output = Sigmoid(output)\n",
        "    self.activations[self.num_layers - 1] = output\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "# dis = Discriminator()\n",
        "# print(dis.forward([1, 2]))\n",
        "\n",
        "#train_loader(train_data, batch_size)[0][0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds_Od0dcMWsc"
      },
      "source": [
        "#### Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM4GfG_cMZeO",
        "outputId": "df4f9bd4-d81d-47db-e02d-dac2505cb42b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.36160100000000006\n",
            "DerivativeQuadraticLoss y:0.99, a:0.01, loss derivative:[-0.98, -0.98]\n",
            "[-0.98, -0.98]\n",
            "-3.3337356988297464\n",
            "[99.01010101010101, 99.01010101010101]\n"
          ]
        }
      ],
      "source": [
        "def QuadraticLoss(y_desired, a_output):\n",
        "  loss = 0\n",
        "\n",
        "  #sum(y - a)^2\n",
        "  for y, a in zip(y_desired, a_output):\n",
        "    loss += (y - a) ** 2\n",
        "\n",
        "  #/2n\n",
        "  loss /= (2 * (len(y_desired)))\n",
        "\n",
        "  return loss\n",
        "\n",
        "def DerivativeQuadraticLoss(y_desired, a_output):\n",
        "  lossderivative = [[] for _ in range(len(a_output))];\n",
        "\n",
        "  for i, (y, a) in enumerate(zip(y_desired, a_output)):\n",
        "    lossderivative[i] = a - y\n",
        "\n",
        "  print(f\"DerivativeQuadraticLoss y:{y}, a:{a}, loss derivative:{lossderivative}\")\n",
        "  return lossderivative\n",
        "\n",
        "#given the 1D tensors output layer's output, desired output, and whetehr to do 'sum' or 'mean' return loss\n",
        "#y_desired and a_output should be between 0 and 1 (this should be true due to sigmoid function)\n",
        "def BinaryCrossEntropyLoss(y_desired, a_output):\n",
        "  loss = 0\n",
        "\n",
        "  for i in range(len(y_desired)):\n",
        "    loss += (y_desired[i] * (math.log(a_output[i], 10))) + ((1 - y_desired[i]) * (math.log(1 - a_output[i], 10)))\n",
        "\n",
        "  return loss\n",
        "\n",
        "def DerivativeBCELoss(y_desired, a_output):\n",
        "  lossderivative = [[] for _ in range(len(a_output))];\n",
        "  for i in range(len(y_desired)):\n",
        "\n",
        "    #if below allowed range, truncate\n",
        "    # if(a_output[i] <= 1e-324):\n",
        "    #   a_output[i] = 1e-300\n",
        "\n",
        "    lossderivative[i] = (y_desired[i] / a_output[i]) + ((1.0 - y_desired[i]) / (1.0 - a_output[i]))\n",
        "    # print(\"DBCEL: lossderivs:\")\n",
        "    # print(y_desired[i] / a_output[i])\n",
        "\n",
        "    # print(\"DBCEL: 1 - desired\")\n",
        "    # print((1.0 - y_desired[i]))\n",
        "\n",
        "    # print(\"DBCEL: output\")\n",
        "    # print(a_output[i])\n",
        "\n",
        "    # print(\"DBCEL: 1 - output\")\n",
        "    # print((1.0 - a_output[i]))\n",
        "\n",
        "  return lossderivative\n",
        "\n",
        "print(QuadraticLoss(([0.9,0.9]),([0.1,0.002])))\n",
        "print(DerivativeQuadraticLoss(([0.99,0.99]),([0.01, 0.01])))\n",
        "\n",
        "\n",
        "print(BinaryCrossEntropyLoss(([0.9,0.9]),([0.1,0.002])))\n",
        "print(DerivativeBCELoss(([0.99,0.99]),([0.01, 0.01])))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJTx5FmgwpSA"
      },
      "source": [
        "#### Backpropogation for Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iivz7a3owsdG"
      },
      "outputs": [],
      "source": [
        "def Backpropogation(input, network, y_desired, forward = True):\n",
        "  #forward propogation (unless specified not to)\n",
        "  if (forward):\n",
        "    final_output = network.forward(input)\n",
        "  else: final_output = input #if forward is false, use the input as the output of this network\n",
        "\n",
        "  #last layer index\n",
        "  l = network.num_layers - 1\n",
        "  #matrix to store errors of each neuron\n",
        "  errors = [[] for _ in range(network.num_layers)]\n",
        "\n",
        "  d = DerivativeQuadraticLoss(y_desired, final_output)\n",
        "  s = SigmoidPrime(network.zs[l])\n",
        "\n",
        "  # print(d)\n",
        "\n",
        "  last_layer_error = np.multiply(d,s)\n",
        "\n",
        "  errors[l] = last_layer_error\n",
        "\n",
        "  #start on second-to-last layer and go backwards through each layer computing errors\n",
        "  for i in reversed(range(0,network.num_layers - 1)):\n",
        "    # print(network.total_weights)\n",
        "    # print (i)\n",
        "    np.dot(network.total_weights[i + 1].transpose(), errors[i + 1])\n",
        "    previous_layer_error = np.multiply(np.dot(network.total_weights[i + 1].transpose(), errors[i + 1]), SigmoidPrime(network.zs[i]))\n",
        "    errors[i] = previous_layer_error\n",
        "\n",
        "  #get partial derivatives of biases (same as individual neuron error)\n",
        "  biases_gradient = [[] for _ in range(network.num_layers)]\n",
        "  for i in range(network.num_layers):\n",
        "    biases_gradient[i] = errors[i]\n",
        "\n",
        "  #get partial derivatives of weights\n",
        "  weights_gradient = [[] for _ in range(network.num_layers)]\n",
        "  weights_gradient[0] = np.multiply(input, errors[0])\n",
        "\n",
        "  for i in range(1, network.num_layers):\n",
        "    weights_gradient[i] = np.multiply(network.activations[i], errors[i])\n",
        "\n",
        "  return (weights_gradient, biases_gradient)\n",
        "\n",
        "# discriminator = Discriminator()\n",
        "# Backpropogation([1,1], generator, [2,2])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Backpropogation for Generator"
      ],
      "metadata": {
        "id": "cmqXO6XT78IS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compute the weight and bias gradients of the generator using the combined networks as a network\n",
        "def Generator_Backpropogation(input, generator, discriminator, y_desired):\n",
        "  #forward propogation (unless specified not to)\n",
        "  network = generator\n",
        "\n",
        "  final_output = input #use the input as the output of the discriminator\n",
        "\n",
        "  #last layer index\n",
        "  l = network.num_layers - 1\n",
        "  dl = discriminator.num_layers - 1\n",
        "  #matrix to store errors of each neuron\n",
        "  errors = [[] for _ in range(network.num_layers)]\n",
        "  discriminator_errors = [[] for _ in range(discriminator.num_layers)]\n",
        "\n",
        "  print(f\"y_desired:{y_desired}\")\n",
        "  print(f\"final output:{final_output}\")\n",
        "\n",
        "  d = DerivativeQuadraticLoss(y_desired, final_output)\n",
        "  print(f\"d:{d}\")\n",
        "  s = SigmoidPrime(discriminator.zs[dl])\n",
        "  print(f\"zs:{discriminator.zs}\")\n",
        "\n",
        "  print(f\"s:{s}\")\n",
        "\n",
        "  last_layer_error = np.multiply(d,s)\n",
        "\n",
        "  discriminator_errors[dl] = last_layer_error\n",
        "\n",
        "  #start on second-to-last layer and go backwards through each layer computing errors\n",
        "  for i in reversed(range(0,network.num_layers + discriminator.num_layers - 1)):\n",
        "    #discriminator layer index (if it's negative, we're no longer iterating on the discriminator)\n",
        "    di = i - network.num_layers\n",
        "\n",
        "    if(i > network.num_layers - 1):\n",
        "      np.dot(discriminator.total_weights[di + 1].transpose(), discriminator_errors[di + 1])\n",
        "      previous_layer_error = np.dot(discriminator.total_weights[di + 1].transpose(), discriminator_errors[di + 1])\n",
        "      discriminator_errors[di] = previous_layer_error\n",
        "\n",
        "    if(i == network.num_layers - 1):\n",
        "      np.dot(discriminator.total_weights[di + 1].transpose(), discriminator_errors[di + 1])\n",
        "      previous_layer_error = np.dot(discriminator.total_weights[di + 1].transpose(), discriminator_errors[di + 1])\n",
        "      errors[i] = previous_layer_error\n",
        "\n",
        "    if(i < network.num_layers - 1):\n",
        "      np.dot(network.total_weights[i + 1].transpose(), errors[i + 1])\n",
        "      previous_layer_error = np.dot(network.total_weights[i + 1].transpose(), errors[i + 1])\n",
        "      errors[i] = previous_layer_error\n",
        "\n",
        "  #get partial derivatives of biases (same as individual neuron error)\n",
        "  biases_gradient = [[] for _ in range(network.num_layers)]\n",
        "  for i in range(network.num_layers):\n",
        "    biases_gradient[i] = errors[i]\n",
        "\n",
        "  #get partial derivatives of weights\n",
        "  weights_gradient = [[] for _ in range(network.num_layers)]\n",
        "  weights_gradient[0] = np.multiply(input, errors[0])\n",
        "\n",
        "  for i in range(1, network.num_layers):\n",
        "    weights_gradient[i] = np.multiply(network.activations[i], errors[i])\n",
        "\n",
        "  return (weights_gradient, biases_gradient)\n",
        "\n",
        "discriminat = Discriminator()\n",
        "generat = Generator()\n",
        "\n",
        "disoutput = discriminat.forward(generat.forward([0.4, 0.2]))\n",
        "print(disoutput)\n",
        "Generator_Backpropogation(disoutput, generat, discriminat, [0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN-Pxt6S7-jP",
        "outputId": "f4df0f55-81ca-435c-ba44-63aff64d200f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.001]\n",
            "y_desired:[0]\n",
            "final output:[0.001]\n",
            "DerivativeQuadraticLoss y:0, a:0.001, loss derivative:[0.001]\n",
            "d:[0.001]\n",
            "zs:[array([ -3.58501933, -10.11986646]), array([-0.22096036,  1.25836108,  3.16735528,  3.01627957,  1.22268555,\n",
            "        2.26283181,  0.45609474, -0.73579549,  5.36077841, -2.26375267,\n",
            "        3.63623117, -4.46535899, -2.17567574,  4.57106479, -2.55368204,\n",
            "        1.69613052]), array([-62.06775405, -44.86082781, -19.76537355,  40.40258295,\n",
            "       -69.87674233,  36.46461163,  14.19258898, -45.26197215]), array([0.24999994])]\n",
            "s:[0.24999994]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([1.82126683e-06, 4.22035302e-06]),\n",
              "  array([-4.41196905e-05,  5.27599582e-05]),\n",
              "  array([ 4.48744431e-05, -7.48950143e-05,  1.62985156e-05, -1.01815963e-05]),\n",
              "  array([-0.00019396,  0.00010234])],\n",
              " [array([7.28506914e-06, 1.68814163e-05]),\n",
              "  array([-8.11639505e-06, -1.96553773e-05]),\n",
              "  array([-1.74431755e-05,  3.56059777e-05, -2.00594438e-05, -3.75606128e-06]),\n",
              "  array([2.61368406e-05, 5.49418937e-06])])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7SljB4rcz5P"
      },
      "source": [
        "#### Optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4dEo90gc3HL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668ca91f-a46e-448e-cab7-2f9963450e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DerivativeQuadraticLoss y:1, a:0.001, loss derivative:[-0.999]\n",
            "DerivativeQuadraticLoss y:2, a:0.9680224864570403, loss derivative:[-1.0319775135429596]\n",
            "DerivativeQuadraticLoss y:2, a:1.0, loss derivative:[-1.0]\n",
            "DerivativeQuadraticLoss y:3, a:1.0, loss derivative:[-2.0]\n",
            "y_desired:[1]\n",
            "final output:[1]\n",
            "DerivativeQuadraticLoss y:1, a:1, loss derivative:[0]\n",
            "d:[0]\n",
            "zs:[array([5.56726469e-04, 3.44263091e-06]), array([0.16934262, 0.2221489 , 0.01815849, 0.0164972 , 0.06081203,\n",
            "       0.02719319, 0.24862428, 0.20693313, 0.00190104, 0.00843692,\n",
            "       0.01004043, 0.00580566, 0.06298382, 0.00251811, 0.06025545,\n",
            "       0.14090526]), array([0.00000000e+00, 0.00000000e+00, 3.02252973e-05, 9.99000000e-04,\n",
            "       0.00000000e+00, 2.22044605e-16, 3.99501493e-04, 0.00000000e+00]), array([0.24759947])]\n",
            "s:[0.24759947]\n",
            "y_desired:[2]\n",
            "final output:[2]\n",
            "DerivativeQuadraticLoss y:2, a:2, loss derivative:[0]\n",
            "d:[0]\n",
            "zs:[array([5.56726469e-04, 3.44263091e-06]), array([0.16934262, 0.2221489 , 0.01815849, 0.0164972 , 0.06081203,\n",
            "       0.02719319, 0.24862428, 0.20693313, 0.00190104, 0.00843692,\n",
            "       0.01004043, 0.00580566, 0.06298382, 0.00251811, 0.06025545,\n",
            "       0.14090526]), array([0.00000000e+00, 0.00000000e+00, 3.02252973e-05, 9.99000000e-04,\n",
            "       0.00000000e+00, 2.22044605e-16, 3.99501493e-04, 0.00000000e+00]), array([0.24620722])]\n",
            "s:[0.24620722]\n",
            "y_desired:[2]\n",
            "final output:[4]\n",
            "DerivativeQuadraticLoss y:2, a:4, loss derivative:[2]\n",
            "d:[2]\n",
            "zs:[array([5.56726469e-04, 3.44263091e-06]), array([0.16934262, 0.2221489 , 0.01815849, 0.0164972 , 0.06081203,\n",
            "       0.02719319, 0.24862428, 0.20693313, 0.00190104, 0.00843692,\n",
            "       0.01004043, 0.00580566, 0.06298382, 0.00251811, 0.06025545,\n",
            "       0.14090526]), array([0.00000000e+00, 0.00000000e+00, 3.02252973e-05, 9.99000000e-04,\n",
            "       0.00000000e+00, 2.22044605e-16, 3.99501493e-04, 0.00000000e+00]), array([0.24624933])]\n",
            "s:[0.24624933]\n",
            "y_desired:[3]\n",
            "final output:[6]\n",
            "DerivativeQuadraticLoss y:3, a:6, loss derivative:[3]\n",
            "d:[3]\n",
            "zs:[array([5.56726469e-04, 3.44263091e-06]), array([0.16934262, 0.2221489 , 0.01815849, 0.0164972 , 0.06081203,\n",
            "       0.02719319, 0.24862428, 0.20693313, 0.00190104, 0.00843692,\n",
            "       0.01004043, 0.00580566, 0.06298382, 0.00251811, 0.06025545,\n",
            "       0.14090526]), array([0.00000000e+00, 0.00000000e+00, 3.02252973e-05, 9.99000000e-04,\n",
            "       0.00000000e+00, 2.22044605e-16, 3.99501493e-04, 0.00000000e+00]), array([0.24624806])]\n",
            "s:[0.24624806]\n"
          ]
        }
      ],
      "source": [
        "from IPython.core import inputtransformer2\n",
        "class StochasticGradientDescentOptimizer():\n",
        "  def __init__(self, lr = 0.1):\n",
        "    self.learning_rate = lr\n",
        "\n",
        "  def update(self, inputs, network, y_desireds, forward = True, sigmoid = False):\n",
        "    for i in range(len(inputs)):\n",
        "      #get weights and biases gradients through forward and backpropogation\n",
        "      (weights_gradient, biases_gradient) = Backpropogation(inputs[i], network, y_desireds[i], forward)\n",
        "      # print(inputs[i])\n",
        "      # print(y_desireds[i])\n",
        "      # print(weights_gradient)\n",
        "      for l in (range(network.num_layers)):\n",
        "        for n in range(len(network.total_weights[l])):\n",
        "          for w in range(len(network.total_weights[l][n])):\n",
        "            network.total_weights[l][n][w] = network.total_weights[l][n][w] - ((self.learning_rate / len(inputs)) * weights_gradient[l][n])\n",
        "            network.total_biases[l][n][w] = network.total_biases[l][n][w] - ((self.learning_rate / len(inputs)) * biases_gradient[l][n])\n",
        "      # print(network.activations[network.num_layers - 1])\n",
        "      # print(network.total_weights[1][1][1])\n",
        "\n",
        "\n",
        "  def update_generator(self, inputs, generator, discriminator, y_desireds):\n",
        "    network = generator\n",
        "    for i in range(len(inputs)):\n",
        "      #get weights and biases gradients through forward and backpropogation\n",
        "      (weights_gradient, biases_gradient) = Generator_Backpropogation(inputs[i], network, discriminator, y_desireds[i])\n",
        "      # print(inputs[i])\n",
        "      # print(y_desireds[i])\n",
        "      # print(weights_gradient)\n",
        "      for l in (range(network.num_layers)):\n",
        "        for n in range(len(network.total_weights[l])):\n",
        "          for w in range(len(network.total_weights[l][n])):\n",
        "            network.total_weights[l][n][w] = network.total_weights[l][n][w] - ((self.learning_rate / len(inputs)) * weights_gradient[l][n])\n",
        "            network.total_biases[l][n][w] = network.total_biases[l][n][w] - ((self.learning_rate / len(inputs)) * biases_gradient[l][n])\n",
        "\n",
        "      # print(network.activations[network.num_layers - 1])\n",
        "      # print(network.total_weights[1][1][1])\n",
        "\n",
        "SGDO = StochasticGradientDescentOptimizer()\n",
        "SGDO.update([[1,1], [2,3], [4, 5], [6,7]], discriminat, [[1], [2], [2], [3]])\n",
        "SGDO.update_generator([[1], [2], [4], [6]], generat, discriminat, [[1], [2], [2], [3]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvqZp0hHG3DY"
      },
      "source": [
        "#### Optimizers II"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T414El_BG50O"
      },
      "outputs": [],
      "source": [
        "#Implementation of Adam optimization\n",
        "class AdamOptimizer():\n",
        "  def __init__(self, lr = 0.1, b1 = 0.9, b2 = 0.999, e = 1e-08):\n",
        "    self.learning_rate = lr\n",
        "    self.beta1 = b1\n",
        "    self.beta2 = b2\n",
        "    self.epsilon = e\n",
        "    self.t_iterations = 0\n",
        "    self.old_m = None\n",
        "    self.old_v = None\n",
        "    self.m_w = None\n",
        "    self.v_w = None\n",
        "    self.m_b = None\n",
        "    self.v_b = None\n",
        "\n",
        "  def update(self, input, network, y_desired, n_iter):\n",
        "    #forwardpropogation\n",
        "    output = network.forward(input)\n",
        "\n",
        "    #backpropogation\n",
        "    weights_gradient, biases_gradient = Backpropogation(input, network, y_desired)\n",
        "\n",
        "    self.m = [np.zeros_like(weight_grad) for weight_grad in weights_gradient]\n",
        "    self.v = [np.zeros_like(weight_grad) for weight_grad in weights_gradient]\n",
        "    #compute gradient\n",
        "\n",
        "    weights_gradient, biases_gradient = Backpropogation(input, network, y_desired)\n",
        "\n",
        "    #calculate first and second moments\n",
        "    for t in (range(n_iter)):\n",
        "      self.ms[self.t] = (self.beta1) * self.ms[self.t - 1] + (1 - self.beta1)*weights_gradient\n",
        "      self.vs[self.t] = (self.beta1) * self.vs[self.t - 1] + (1 - self.beta1)*weights_gradient\n",
        "\n",
        "    #calculate step size and direction\n",
        "\n",
        "    #adjust weights and biases\n",
        "    network.total_biases -= network.total_biases - (learning_rate * self.ms)\n",
        "    network.total_weights -= network.total_weights - (learning_rate * self.ms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OX7rl9fL5OW"
      },
      "source": [
        "#### Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OohF7mX1MAt6"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.05\n",
        "num_epochs = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEX_uwo28HcA"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WojgEreey8Ah"
      },
      "outputs": [],
      "source": [
        "discriminator = Discriminator()\n",
        "generator = Generator()\n",
        "SGD = StochasticGradientDescentOptimizer(learning_rate)\n",
        "\n",
        "right = 0\n",
        "wrong = 0\n",
        "for w in range(1000):\n",
        "  if((SGD.learning_rate > 0.1)):\n",
        "     SGD.learning_rate -= 0.0001\n",
        "  print(f\"learning rate: {SGD.learning_rate}\")\n",
        "\n",
        "  for o, i in enumerate(train_input):\n",
        "    if(o % 100 == 0):\n",
        "      right = 0\n",
        "      wrong = 0\n",
        "      print(\"reset!-------------------------------------\")\n",
        "\n",
        "    # print (f\"Number: {o}\")\n",
        "    # want the discriminator to output 1 for all real data\n",
        "    real_labels = np.ones((1, 1))\n",
        "    #and 0 for all generated data\n",
        "    generated_labels = np.zeros((1, 1))\n",
        "\n",
        "    #input to generator to get generate output (discriminator input)\n",
        "    latent_space = np.random.rand(1, 2)\n",
        "\n",
        "    #we want generated data which we get from the generator\n",
        "    generated = [[] for _ in range(len(latent_space))]\n",
        "    for x, sample in enumerate(latent_space):\n",
        "      # print(sample)\n",
        "      generated[x] = generator.forward(sample)\n",
        "\n",
        "    all_samples = np.concatenate(([i], generated))\n",
        "    all_sample_labels = np.concatenate((real_labels, generated_labels))\n",
        "\n",
        "    SGD.update(all_samples, discriminator, all_sample_labels, sigmoid = True)\n",
        "\n",
        "    if(discriminator.forward(i) >= 0.95):\n",
        "      right += 1\n",
        "      print(f\"real output: {discriminator.forward(i)}\")\n",
        "    else: wrong += 1\n",
        "\n",
        "    if(discriminator.forward(generated[0]) <= 0.05):\n",
        "      right += 1\n",
        "      print(f\"false output: {generated[0]}, {discriminator.forward(generated[0])}\")\n",
        "    else: wrong += 1\n",
        "\n",
        "    # print(f\"generated: {generated[0]}\")\n",
        "    print(f\"accuracy: {right/(right + wrong)}\")\n",
        "\n",
        "    print(f\"discriminator weight: {discriminator.total_weights[2][0]}\")\n",
        "    #####################################\n",
        "    #input to generator for training\n",
        "    latent_space = np.random.rand(1, 2)\n",
        "\n",
        "    #the output of the generator is the discriminators output, which should be 1.\n",
        "    #store output of generator in generated_samples\n",
        "    generated_samples = [[] for _ in latent_space]\n",
        "    for i, input in enumerate(latent_space):\n",
        "      generated_samples[i] = generator.forward(input)\n",
        "\n",
        "    #store output of discriminator from generated input in output_discriminator_generated\n",
        "    output_discriminator_generated = [[] for I in generated_samples]\n",
        "    for i, input in enumerate(generated_samples):\n",
        "      output_discriminator_generated[i] = discriminator.forward(input)\n",
        "\n",
        "    #compute gradients of generator using output of discriminator and update using SGD\n",
        "    #Specifies no forwardprop in the function itself\n",
        "    SGD.update_generator(output_discriminator_generated, generator, discriminator, real_labels)\n",
        "\n",
        "  print(discriminator.forward(train_input[4]))\n",
        "  print(discriminator.forward(train_input[200]))\n",
        "  print(discriminator.forward(train_input[134]))\n",
        "  print(discriminator.forward(train_input[800]))\n",
        "  print(discriminator.forward(train_input[20]))\n",
        "  print(discriminator.forward(train_input[520]))\n",
        "  print(discriminator.forward([-5, 4]))\n",
        "  print(discriminator.forward([-25, -10]))\n",
        "  print(discriminator.forward([13, -10]))\n",
        "  # print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKXX-zGIP8Ck"
      },
      "outputs": [],
      "source": [
        "rlatent_space = np.random.rand(1, 2)\n",
        "#we want generated data which we get from the generator\n",
        "\n",
        "rgenerated = [[] for _ in range(len(rlatent_space))]\n",
        "for x, sample in enumerate(rlatent_space):\n",
        "  rgenerated[x] = generator.forward(sample)\n",
        "  print(rgenerated[x])\n",
        "\n",
        "print(discriminator.forward([-5, 4]))\n",
        "print(discriminator.forward([-5, -10]))\n",
        "print(discriminator.forward([-13, 12]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39E_ujQe8Kcy"
      },
      "outputs": [],
      "source": [
        "discriminator = Discriminator()\n",
        "generator = Generator()\n",
        "SGD = StochasticGradientDescentOptimizer()\n",
        "\n",
        "for epoch in range(num_epochs):#for each epoch\n",
        "  for n, batch in enumerate(train_loader(train_data, batch_size)):#for each batch in the epoch\n",
        "    print(n)\n",
        "    print(\"-----------------------------------------------\")\n",
        "    #want the discriminator to output 1 for all real data\n",
        "    real_labels = np.ones((batch_size, 1))\n",
        "    #and 0 for all generated data\n",
        "    generated_labels = np.zeros((batch_size, 1))\n",
        "\n",
        "    #input to generator to get generate output (discriminator input)\n",
        "    latent_space = np.random.rand(batch_size, 2)\n",
        "\n",
        "    #we want generated data which we get from the generator\n",
        "    generated = [[] for _ in range(len(latent_space))]\n",
        "    for i, sample in enumerate(latent_space):\n",
        "      # print(sample)\n",
        "      generated[i] = generator.forward(sample)\n",
        "\n",
        "    print(generated[1])\n",
        "\n",
        "    #isolate batch_input\n",
        "    batch_input = [[] for _ in range(len(batch))]\n",
        "    for i, item in enumerate(batch):\n",
        "      batch_input[i] = item[0]\n",
        "\n",
        "    # print(batch_input)\n",
        "    #we want to input both real and generated samples into the discriminator\n",
        "    all_samples = np.concatenate((batch_input, generated))\n",
        "    all_sample_labels = np.concatenate((real_labels, generated_labels))\n",
        "\n",
        "    #shuffle data but keep it corresponding\n",
        "    # assert len(all_samples) == len(all_sample_labels)\n",
        "    # p = np.random.permutation(len(all_samples))\n",
        "    # all_samples = all_samples[p]\n",
        "    # all_sample_labels = all_sample_labels[p]\n",
        "\n",
        "    # print(f\"generated: {generated}\")\n",
        "\n",
        "    # print(\"one\")\n",
        "    #train the discriminator\n",
        "    SGD.update(all_samples, discriminator, all_sample_labels)\n",
        "    # print(\"two\")\n",
        "\n",
        "    #input to generator for training\n",
        "    latent_space = np.random.rand(batch_size, 2)\n",
        "\n",
        "    #the output of the generator is the discriminators output, which should be 1.\n",
        "    #store output of generator in generated_samples\n",
        "    generated_samples = [[] for _ in latent_space]\n",
        "    for i, input in enumerate(latent_space):\n",
        "      generated_samples[i] = generator.forward(input)\n",
        "\n",
        "    #store output of discriminator from generated input in output_discriminator_generated\n",
        "    output_discriminator_generated = [[] for I in generated_samples]\n",
        "    for i, input in enumerate(generated_samples):\n",
        "      output_discriminator_generated[i] = discriminator.forward(input)\n",
        "\n",
        "    #compute gradients of generator using output of discriminator and update using SGD\n",
        "      #Specifies no forwardprop in the function itself\n",
        "    SGD.update(output_discriminator_generated, generator, real_labels, forward = False)\n",
        "\n",
        "    if epoch % 10 == 0 and n == batch_size - 1:\n",
        "      print(f\"Epoch: {epoch}   Loss D: {discriminator.activations[discriminator.num_layers - 1]}\")\n",
        "      print(f\"Epoch: {epoch}   Loss G: {generator.activations[generator.num_layers - 1]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylD7GSN2ske8"
      },
      "outputs": [],
      "source": [
        "lssamples = np.random.rand(100,2)\n",
        "\n",
        "generatedsamples = [[] for _ in lssamples]\n",
        "\n",
        "for i, l in enumerate(lssamples):\n",
        "  generatedsamples[i] = generator.forward(l)\n",
        "  matplotlib.pyplot.plot(generatedsamples[i][0], generatedsamples[i][1],\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6QtXPQaCGq8"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "rEGC6Me-Wcgc",
        "z6SorvfyWV69",
        "1w-b1CnjWOQY",
        "uJTx5FmgwpSA",
        "OvqZp0hHG3DY",
        "_OX7rl9fL5OW"
      ],
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPdEgLegOcScMZztZRBoA/X",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}